{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f54d666c-c628-4e5b-9bd2-c2202bc9f892",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27f65e-e28c-4e2e-83d2-99f62dc46b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57105d-6490-401e-a9a2-9788657c2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data pd.read_csv（“ecommerce.csv\"）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b5b2c-bc11-4b14-ad27-e49edde36482",
   "metadata": {},
   "outputs": [],
   "source": [
    "original data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf146007-d494-4afb-9818-3f64b8dc53fe",
   "metadata": {},
   "source": [
    "# 评估数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a542e6-6653-433f-94a7-3c4a2b426f31",
   "metadata": {},
   "source": [
    "### 评估数据整齐度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4808f-f892-4f2b-82ae-4581e21bc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "original data.sample（10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7571d7e-dc33-4548-9d10-a51771dfc2ef",
   "metadata": {},
   "source": [
    "### 评估数据干净度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83732c5a-556c-4d15-9488-e068152d4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "originaldata.info()缺失值、时间、字符串、浮点数等的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73908f1-a566-43af-a38e-931da55e19ac",
   "metadata": {},
   "source": [
    "#### 评估缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02eeed2-2c8d-4042-93f5-b2189d312dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "original data[original data[\"Description\"].isnull()]\n",
    "original data[（original data[\"Description\"].isnull())&（original data[\"UnitPrice\"], != 0)]\n",
    "不具备评估意义，可以删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0c976-3e2d-4f38-8fc5-01fa810f7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data[original_data[\"CustomerID\"].isnull()]\n",
    "缺失，但不影响评估，可以保留"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8d64e-f1b6-4d75-9c5b-898b70ff648f",
   "metadata": {},
   "source": [
    "#### 评估重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd92555-3f3b-4843-8061-0ff18e2dbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "是否为唯一标识符，或者确认是否可以重复，一个客户单可以购买很多商品"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09dd173-6815-4a33-b1fa-dba5ab2448e1",
   "metadata": {},
   "source": [
    "#### 评估不一致数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d493c1a-e752-42c1-aca5-f10304d3c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original data[\"Country\"].value_counts()\n",
    "United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd302b-41a2-4c10-8d6c-d69a7889777d",
   "metadata": {},
   "source": [
    "#### 评估无效或错误数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f62551-379a-4828-b206-47d89ab6953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88fcfe4-f61b-4135-bca2-a0c95d42201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quantity存在大量负数\n",
    "original_data[original_data[\"Quantity\"]< 0]如果这个代码以字母“c开头，表示这笔交易被取消\n",
    "验证\n",
    "original_data[（original_data[\"Quantity\"]<0)&（original_data[\"InvoiceNo\"].str[0]!=“C\"）\n",
    "存在不退货也为0\n",
    "验证\n",
    "original data[（originaldata[\"Quantity\"]<0)&（original_data[\"InvoiceNo\"].str[0]!=“C\"）&(original data[\"UnitPrice\"l !=0)\n",
    "Quantity存在大量负数因为取消和价格为0\n",
    "需要全部删除\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82cc67-077b-441f-aa7c-fb5cfaef5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "original data[original data[\"UnitPrice\"]< 0]\n",
    "UnitPrice有小于0的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39204b-12ba-46df-8485-d86390fbe677",
   "metadata": {},
   "outputs": [],
   "source": [
    "列出清理代办\n",
    "把InvoiceDate变量的数据类型转换为为日期时间\n",
    "把CustomerID变量的数据类型转换为字符串\n",
    "把Description变量缺失的观察值删除\n",
    "把Country变量值“uSA替换为“United States\n",
    "把country变量值“uk”、“u.K.”替换为“United Kingdom”\n",
    "把Quantity变量值为负数的观察值删除\n",
    "把UnitPrice变量值为负数的观察值删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bc542-a146-4fc9-915e-4e8ab7aacca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned data = original data.copy()\n",
    "验证cleaned data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4505789-8ce4-4df0-88a6-70f5e9ca8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "把InvoiceDate变量的数据类型转换为为日期时间pd.to_datetime\n",
    "    cleaneddata[\"InvoiceDate\"] = pd.to_datetime（cleaned_data[\"InvoiceDate\"])\n",
    "把CustomerID变量的数据类型转换为字符串：\n",
    "    cleaned data[\"CustomerID\"] = cleaned data[\"CustomerID\"].astype(str)\n",
    "        客户编号额外增加了小数点需删除.0\n",
    "        cleaneddata[\"CustomerID\"]=cleaned data[\"CustomerID\"].str.slice(0,-2)\n",
    "把Description变量缺失的观察值删除，并查看删除后该列空缺值个数和：\n",
    "    cleaned_data.dropna(subset=[\"Description\"], inplace=True)\n",
    "    验证清理是否完成cleaned data[\"Description\"].isnull().sum()\n",
    "把country变量值\"uSA替换为\"UnitedStates\n",
    "    cleaned_data[\"Country\"] =cleaned_data[\"Country\"].replace((\"usA\":\"United States\"))\n",
    "    验证len(cleaned_data[cleaned_data[\"Country\"]==\"USA\"])\n",
    "把Country变量值“uK”、“U.K.”替换为“United Kingdom”，并检查替换后“UK”和“U.K.”变量值个数：\n",
    "    cleaned_data[\"Country\"] = cleaned_data[\"Country\"].replace（(\"UK\":“United Kingdom”,\"U.k.\":\"United Kingdom\"})\n",
    "    验证print(len(cleaned data[cleaned data[\"Country\"]\"UK\"]）)\n",
    "        print(len(cleaned_data[cleaned data[\"Country\"]\"U.K.“1))\n",
    "把Quantity变量值为负数的观察值删除，并检查替换后Quantity变量值为负数的个数：筛选出大于0的\n",
    "    clened data = cleaned_data[cleaned_data[\"Quantity\"]>=01]\n",
    "    验证len(cleaned_data[cleaned_data[\"Quantity\"] <0])\n",
    "    cleaned data = cleaned data[cleaned_data[\"UnitPrice\"] >= 0]\n",
    "    验证len(cleaned_data[cleaned data[\"UnitPrice\"] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31317d3-219d-4da8-bf2b-ec3d77d72929",
   "metadata": {},
   "source": [
    "# 保存清理后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9dae2-9584-49c2-a827-d29fdf332e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned data.to csv(\"e commerce _cleaned.csv\", index=False)\n",
    "验证\n",
    "pd.read_csv(\"e_commerce_cleaned.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40943b99-290b-45e7-b218-a5bc79fe332b",
   "metadata": {},
   "source": [
    "# 如何把输出项目放到Github简历上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbef006-0c55-4660-a017-9feb3b227db7",
   "metadata": {},
   "source": [
    "# 继续深度整理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca81ce3-4c15-447a-a50b-bfbdd30ef8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "合并多数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d873e-ebdd-4994-b771-ee1b25af9edb",
   "metadata": {},
   "source": [
    "纵向拼接df1和df22（忽略索引）\n",
    "    pd.concat（[dfl,df2],ignore_index（= True)\n",
    "横向拼接DataFrame\n",
    "    pd.concat([df3,df4],axis=1)\n",
    "根据\"客户ID\"合并customer_df和order_df\n",
    "    pd.merge（customer_df，order_df，on='客户ID'）  on为可选参数\n",
    "    根据“客户ID\"和“订单日期”合并order_df2和customer_df2\n",
    "    pd.merge（order_df2,customer_df2，on=[客户ID“订单日期“1）\n",
    "两列各不相同，合并\n",
    "    pd.merge（order_df3，customer_df3，left_on=['客户编号'，‘订单日期），right_on=[\"客户ID\"，\"交易日期\"]\n",
    "合并两个表，列名相同，但数据不同\n",
    "    pd.merge（df7，df8，on=[\"日期\"，\"店铺”],suffixes=['_df7'，‘df8‘]）\n",
    "    pd.merge(df1， df2， on=\"客户ID\"， how=\"inner\")  它的值可以是inner、outer、left、right\n",
    "    \n",
    "join合并方法，看索引合并。有重名列会报错，需要指定列名的后缀\n",
    "customer_df4.join(order_df4,how='inner',lsuffix='_customer', rsuffix='_order'）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c64117-c968-4573-a964-e44e48fee4d3",
   "metadata": {},
   "source": [
    "重塑数据-分组聚合groupby—类似于excel的筛选\n",
    "df.groupby（“分店编号\"）[“销售额\"].mean()\n",
    "groupby（'分店编号'）[[\"销售额\"，“销售数量\"]].mean（）\n",
    "df.groupby([\"分店编号\",\"时间段\"])[[\"销售额\",\"销售数量\"]].mean（）\n",
    "聚合函数，自定义函数+aplply!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "def max_plus_10（nums):\n",
    "    return nums.max()+10\n",
    "df.groupby([“分店编号”，“时间段\"])[[“销售额”，“销售数量\"]].appLy（max_plus_10）\n",
    "\n",
    "聚合运算-使用透视表pd.pivot_table\n",
    "pd.pivot_table（df,index=[\"分店编号\",\"时间段”],coLumns=\"商品类别”,vaLues=\"销售额\",aggfunc=np.sum)         aggfunc为聚合惭怍\n",
    "pd.pivot table（df.index=\"商品类别,coLumns=“分店编号”,values=\"销售额\"，aggfunc=np.sum）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f285a3-eafa-4a41-9deb-d23df5bfa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "数据整理-分箱bins-切片cut-结合groupby-query\n",
    "    age_bins=[0,10,20,30,40,50,60,120]\n",
    "    pd.cut（df1[\"年龄\"]，age_bins）\n",
    "数据范围对应的标签\n",
    "age_labels=['儿童','青少年',‘青年',壮年','中年','中老年','老年']\n",
    "pd.cut（df1[\"年龄\"]，age_bins,labels=age_labels)\n",
    "根据标签进行分组（年龄组）分析\n",
    "df1.groupby（“年龄组\"）[\"工资\"].mean（）\n",
    "\n",
    "#提取grouped_df2索引l为001的行\n",
    "grouped_df2.loc[\"001\"]\n",
    "#重置grouped_df2的索引\n",
    "grouped_df2.reset_index()\n",
    "\n",
    "#用query方法筛选出性别为男且年龄小于或等于20岁的观察值\n",
    "df1.query(‘(性别 == “男”’)&（年龄<=20)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70efccb-c159-4294-bf8e-577bc28df93e",
   "metadata": {},
   "source": [
    "## 项目实战IMDB的流派高分演员挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbe5a5-4862-4c35-9da5-4f348ce6e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "连接作品信息表和演员信息表\n",
    "credits_with_titles = pd.merge(cleaned_credits,cleaned_titles,on=\"id\",how=\"inner\")\n",
    "删除导演的行\n",
    "actor_with_titles=credits_with_titles.query('role ==\"ACToR\"')\n",
    "人员分组\n",
    "groupby_genres_and_person_id = actor_with_titles.groupby([\"genres\",\"person_id\"])\n",
    "对评分进行聚合运算\n",
    "imdb_score_groupby_genres_and_person_id = groupby_genres_and_person_id [\"imdb_score\"].mean()\n",
    "imdb_score_groupby_genres_and_person_id\n",
    "我们可以调用reset_index，对层次化索引进行重置，得到更加规整的DataFrame。\n",
    "imdb_score_groupby_genres_and_person_id_df =imdb_score_groupby_genres_and_person_id.reset_index(）\n",
    "imdb_score_groupby_genres_and_person_id_df\n",
    "找到最高评分\n",
    "genres_max_scores =imdb_score_groupby_genres_and_person_id_df.groupby(\"genres\")[\"imdb_score\"].max()\n",
    "genres_max_scores\n",
    "！！！通过merge连接-对应到具体的人名\n",
    "pd.merge(imdb_score_groupby_genres_and_person_id_df,genres_max_scores,on=[\"genres\",\"imdb_score\"])\n",
    "演员不止一部电影，删除重复的数据\n",
    "actor_id_with_names =cleaned_credits[['person_id','name']].drop_duplicates()\n",
    "actor_id_with names.head（10)\n",
    "增加人名并对应最高分\n",
    "genres_max_score_with_actor_name = pd.merge(genres_max_score_with_person_id,,actor_id_with_names，on=\"person_id\"）\n",
    "genres_max_score_with_actor_name\n",
    "以流派进行排名\n",
    "A=genres_max_score_with_actor_name.sort_values(\"genres\").reset_index().drop(\"index\"axis=1)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50612bc-3ee8-4eb7-ae75-56272aec45cd",
   "metadata": {},
   "source": [
    "# 数据可视化——x100s的截图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bafb7cb-2e01-4d95-a1ee-f7b50c64d145",
   "metadata": {},
   "source": [
    "### 统计学和项目实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf84fe-b32b-4ab8-bf13-f8e30f5726b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "描述统计学                       推断统计学\n",
    "对数据进行描述和总结              通过样本做出关于总体的推断或预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0621b-233f-4e27-a808-6256d8ef3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "t检验\n",
    "from scipy.stats import ttest_ind\n",
    "t越大代表两个样本的差异越显著，p越小代表这种显著情况越真实，概率越高，拒绝原假设，P值不能直接告诉我们效应的大小或重要性，它只告诉我们结果的偶然性有多高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122a9140-94e2-47bf-acd2-2f29f43b3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "两地区身高是否有差异\n",
    "#进行t检验\n",
    "t_stat,p_value = ttest_ind(region_a_height,region_b_height)\n",
    "print(t_stat, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37405b-0e67-4d60-a76f-fc9c75a633c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_a_height=height_df[height_df['地区']=='A']['身高']\n",
    "region_b_height=height_df[height_df['地区']==‘B']['身高']\n",
    "#进行t检验\n",
    "t_stat, p_value = ttest_ind(region_a_height, region_b_height)\n",
    "print(t_stat, p_value)\n",
    "#判断显著性\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "print（'两组数据有显著差异'）\n",
    "else:\n",
    "print（'两组数据无显著差异'）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24407d35-af8a-41fe-bf32-9c1755ff8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "鸢尾花两物种分析\n",
    "from sscipy.stats import ttest_ind\n",
    "\n",
    "sns.histplot(iris_setosa['SepalLengthCm'],binwidth=0.1)\n",
    "sns.histplot(iris_versicolor['SepalLengthCm'],binwidth=0.1)\n",
    "plt.show()\n",
    "\n",
    "t_stat,p_value = ttest_ind(iris_setosa['SepalLengthCm'],iris_versicolor['SepalLengthCm'])\n",
    "print(f\"t值:{t_stat}\")\n",
    "print（f\"p值：{p_value}\")\n",
    "t值：-10.52098626754911\n",
    "p值：8.985235037487079e-18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a221c-3153-4b81-95c5-4ba8c7cd7867",
   "metadata": {},
   "source": [
    "## 机器学习-线性回归-OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d6512-fec5-4a0e-bbb2-7ed7d1950389",
   "metadata": {},
   "outputs": [],
   "source": [
    "预测房价小实践\n",
    "import statsmodels.api as sm\n",
    "就是用来把分类变量转成虚拟变量的pd.get_dummies(data， columns=[\"所在城市\"],dtype=int,drop.first=True)剔除共线性\n",
    "\n",
    "y=data［'价格'］\n",
    "×=data[['面积'，‘所在城市_B']]\n",
    "X = data.drop('价格',aaxis=1)\n",
    "X=data.drop(［'价格','所在城市_A'］,axis=1)\n",
    "\n",
    "如何检萱自变量之间的相关性\n",
    "x['面积'].corr(x['卧室数'])\n",
    "全面检查相关性||>0.8的剔除，[DataFrame名].corr   生成一个判断的矩阵，转化为热力图sns.heatmap(x.corr().abs(),annot=True)   plt.plot()\n",
    "\n",
    "传入自变量作为参数\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "#建立线性回归模型\n",
    "Ordinary Least Squares=OLS=最小二乘法\n",
    "modelsm.OLS(y, x)\n",
    "\n",
    "对数据进行拟合（系数coef是coefficient的意思）！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "result= sm.OLS(y, X).fit()\n",
    "result.summary()\n",
    "评估P值和R方\n",
    "\n",
    "总之机器学习就是这样，很多时候没有标准答案，需要我们不断地尝试、调整、验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9ea96-6f25-4c83-9c2f-77ec8fc0b9a8",
   "metadata": {},
   "source": [
    "## 线性回归实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59058d44-172a-4f4f-8308-314cda1480be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "引入虚拟变量，建立数据拷贝\n",
    "lr_house_price = cleaned_house_price.copy()\n",
    "用0或1判断是否属于这个分类变量\n",
    "    lr_house_price = pd.get_dummies(lr_house_price, drop_first=True, columns=['mainroad','guestroom',\n",
    "                                                                                'basement', 'hotwaterheating',\n",
    "                                                                                'airconditioning','prefarea',\n",
    "                                                                                'furnishingstatus'],dtype=int)\n",
    "    lr_house_price\n",
    "\n",
    "划分自变量和因变量(检查自变量的相关性)\n",
    "y = lr_house_price['price']\n",
    "X = lr_house_price.drop（'price',axis=1)\n",
    "x.corr().abs()>0.8\n",
    "不需要移除变量\n",
    "\n",
    "给线性方程添加截距\n",
    "X = sm.add_constant（x)\n",
    "X\n",
    "\n",
    "拟合回归分析\n",
    "model = Sm.OLS（y,X).fit（)\n",
    "model.summary()\n",
    "\n",
    "移除P值很大的自变量，对预测没有影响的X\n",
    "x=X.drop（['const','bedroomsishingstatus_semi-furnished'],axis=1)\n",
    "\n",
    "再次回归分析\n",
    "modelSm.OLS（y,x).fit()\n",
    "model.summary()\n",
    "\n",
    "coef为正正相关，为负值是负相关\n",
    "\n",
    "进行预测任务：\n",
    "price_to_predict = pd.DataFrame({'area':[5600],'bedrooms':[4],'bathrooms':[2],\n",
    "                                'stories':[2],‘mainroad':['no'],'guestroom':['no'],\n",
    "                                'basement':['yes'],'hotwaterheating':['yes'],\n",
    "                                'airconditioning':['no'],'parking':2,prefarea':['yes'],\n",
    "                                'furnishingstatus':['semi-furnished'l})\n",
    "price_to_predict\n",
    "\n",
    "我们需要把分类变量的类型转换为Category，并且通过categories参数，让程序知道所有可能的分类值。这样做的原因是，预测数据包含的分类可能不全。我们需要确\n",
    "保引入虚拟变量的时候，不会漏掉某个或某些分类。\n",
    "price_to_predict['mainroadcategories='no'yes'])\n",
    "price_to_predict['guestroompd.Categoricalcategories='no'yes'])\n",
    "price_to_predict['basement']pd.Categoricacategories=['no'yes'1)\n",
    "price_to_predict['hotwaterheating']l(price_to predict[['hotwaterheating'],categories=['no''yes']）\n",
    "price_to_predict['airconditioning']= pd.Categorical(price_to_predict['airconditioning'l,categories=['no'yes`1）\n",
    "price_to_predict['prefarea']pd.Categorical(price_to_predictI'prefareacategories=['no'ves'I)\n",
    "\n",
    "下一步，对分类变量引入虚拟变量。\n",
    "price_to_predict=pd.get_dummies(price_to_predict,drop_first=True,\n",
    "                                columns=['mainroad','guestroom',\n",
    "                                'basement','hotwaterheating',\n",
    "                                'airconditioning','prefarea',\n",
    "                                'furnishingstatus'],dtype=int)\n",
    "price_to_predict.head()          \n",
    "\n",
    "删除不需要的自变量\n",
    "price_to_predict = price_to_predict.drop(['bedrooms','furnishingstatus_semi-furnished'],axis=1)\n",
    "\n",
    "接下来就可以调用线性回归模型的predict方法，获得预测价格。\n",
    "predicted_value = model.predict(price_to_predict)\n",
    "predicted_value\n",
    "7.071927e+06\n",
    "dtype:float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668c7fa-ab62-43bb-9ec7-0ceb9adfde1a",
   "metadata": {},
   "source": [
    "# 机器学习-逻辑回归——处理二分类问题，输出[0,1]的概率——最大似然估计Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d5394-b5f3-4529-bfbf-d5e2716496bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "创建虚拟变量\n",
    "pd.get_dummies(data,\n",
    "            columns=[\"gender\", \"smoking\"],\n",
    "            dtype=int,\n",
    "            drop_first=True)\n",
    "\n",
    "自变量的相关性检查\n",
    "logistics_data.corr().abs()>0.8\n",
    "\n",
    "y = logistics_data['cancer']\n",
    "X = logistics_data.drop('cancer', axis=1)\n",
    "\n",
    "传入自变量作为参数\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "#建立逻辑回归模型\n",
    "result = sm.Logit(y, X).fit()\n",
    "result.summary()\n",
    "\n",
    "计算coef自然常数的次方，获得概率\n",
    "print(np.exp(1.8148))\n",
    "print(np.exp(4.4339))\n",
    "6.139848085022786\n",
    "84.25938856524215\n",
    "\n",
    "预测新数据\n",
    "result.predict(..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4cc7d-0f90-43c3-b058-22328174357c",
   "metadata": {},
   "source": [
    "## 逻辑回归实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b897d-0fe0-4838-8183-2fa88267aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "复制\n",
    "lr_titanic_train =cleaned_titanic_train.copy()\n",
    "lr_titanic_train.head（)\n",
    "移除不相关的列\n",
    "lr_titanic_train =lr_titanic_train.drop（['PassengerId','Name','Ticket','Cabin',‘Embarked'],axis=1)\n",
    "lr_titanic_train.head()\n",
    "\n",
    "虚拟变量\n",
    "lr_titanic_train = pd.get_dummies（lr_titanic_train,drop_first=True, columns=['Pclass','Sex'],dtype=int)\n",
    "lr_titanic_train.head()\n",
    "\n",
    "自变量和因变量划分-检查相关性\n",
    "lr_titanic_train['Survived']\n",
    "X= lr_titanic_train.drop（['Survived'],axis=1)\n",
    "x.corr()\n",
    "绝对值大于0.8 abs\n",
    "X.corr().abs()>0.8\n",
    "删除Parch'，'SibSp的因变量，大于了0.8\n",
    "X=X.drop（['Parch'，'SibSp'],axis=1)\n",
    "\n",
    "添加截距\n",
    "Xsm.add_constant(x)\n",
    "\n",
    "逻辑回归\n",
    "modelsm.Logit（y,x).fit（)\n",
    "model.summary()\n",
    "\n",
    "观察P值，移除不想关的自变量，再次回归分析\n",
    "X=X.drop（[Fare'],axis=1)\n",
    "modelsm.Logit（y,x).fit（)\n",
    "model.summary()\n",
    "\n",
    "观察系数coef的相关性，并转化为e的次方，获得概率numpy的exp\n",
    "#年龄\n",
    "np.exp(-0.0395）\n",
    "0.9612699539905982\n",
    "以上结果说明，年龄每增加1岁，生还概率降低4%左右。\n",
    "#Fami LyNum\n",
    "np.exp（-0.2186)\n",
    "0.803643111115195\n",
    "以上结果说明，每多一名同乘家庭成员，生还概率降低20%左右。\n",
    "#Pclass_2\n",
    "np.exp（-1.1798）\n",
    "0.30734020049483596\n",
    "以上结果说明，二等舱乘客的生还概率比一等舱乘客低71%左右。\n",
    "#Pclass_3\n",
    "np.exp（-2.3458)\n",
    "0.09577055503172162\n",
    "以上结果说明，三等舱乘客的生还概率比一等舱乘客低90%左右。\n",
    "#Sex male\n",
    "np.exp(-2.7854)\n",
    "0.061704402333015156\n",
    "以上结果说明，男性乘客的生还概率比女性乘客低94%左右。\n",
    "\n",
    "根据模型参数值，我们总结：\n",
    "        年龄小的乘客幸存概率更高；\n",
    "        女性乘客的生还率比男性乘客的幸存概率更高；\n",
    "        来自的船舱等级高的乘客幸存概率更高；\n",
    "        同乘家庭成员少的乘客幸存概率更高\n",
    "\n",
    "预测新的测试文件\n",
    "年龄有缺失数据，用平均数替代\n",
    "titanic_test['Age'] = titanic_test['Age'].fillna(titanic_test['Age'].mean())\n",
    "titanic_test['Age'].isna().sum()\n",
    "\n",
    "引入虚拟变量，先分类变量\n",
    "titanic_test['Pclass'] = pd.Categorical(titanic_test['Pclass'],categories=['1',\n",
    "titanic_test['Sex'] =pd.Categorical(titanic_test['Sex'],categories=['female','male'])\n",
    "titanic_test['Embarked'] = pd.Categorical(titanic_test['Sex'],categories=['C','Q','S'])\n",
    "\n",
    "引入\n",
    "titanic_test = pd.get_dummies（tdrop_tirst=rrue,columns=[·Pclass','Sex'],dtype=int）\n",
    "titanic_test.head（)\n",
    "\n",
    "查看一下模型需要的输入变量\n",
    "model.params\n",
    "\n",
    "由于我们在数据整理步骤建立了FamilyNum变量，此处也需要对预测数据加上此变量。\n",
    "titanic_test['FamilyNum']= titanic_test['SibSp']+ titanic_test['Parch']\n",
    "titanic_test.head()\n",
    "\n",
    "接下来构建我们要输入给模型进行预测的变量，需要和模型训练时的输入一致。\n",
    "X_test = titanic_test[['Age','FamilyNum','Pclass_2','Pclass_3','Sex_male']]\n",
    "X_test = sm.add_constant（x_test)\n",
    "\n",
    "现在就可以调用逻辑回归模型的predict方法，获得预测的幸存概率。\n",
    "predicted_value = model.predict(X_test)\n",
    "predicted_value\n",
    "\n",
    "predicted_valuee>0.5\n",
    "概率大于等于0.5的预测为幸存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
